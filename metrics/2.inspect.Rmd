---
title: "Inspect metrics"
output: html_notebook
params:
  input_metrics_file_prefix: "results/c9ee9c34/metrics"
  background_type: "ref"
---

```{r}
library(tidyverse)
library(glue)
library(logger)
```

```{r}
type <- params$background_type
```

```{r}
metric_set <- glue("level_1_0_{type}_null_adjusted")

parquet_file <-
  with(
    params,
    glue("{input_metrics_file_prefix}_{metric_set}.parquet")
  )

log_info("Reading {parquet_file} ...")

level_1_0_metrics_null_adjusted <-
  arrow::read_parquet(glue(parquet_file))

all_same_cols_rep <- attr(level_1_0_metrics_null_adjusted, "all_same_cols_rep")
```

After reading level_1, drop duplicates that may result from annotating
level 1_0 entities

```{r}
metric_set <- glue("level_1_{type}_null_adjusted")

parquet_file <-
  with(
    params,
    glue("{input_metrics_file_prefix}_{metric_set}.parquet")
  )

log_info("Reading {parquet_file} ...")

level_1_metrics_null_adjusted <-
  arrow::read_parquet(glue(parquet_file)) %>%
  select(all_of(all_same_cols_rep), matches("^sim_")) %>%
  distinct()
```

```{r}
significance_threshold <-
  attr(level_1_0_metrics_null_adjusted, "significance_threshold")

significance_threshold
```


```{r}
metric_list <-
  c(
    glue("sim_retrieval_average_precision_{type}_i_mean_i"),
    glue("sim_retrieval_average_precision_{type}_i_nlog10pvalue_mean_i")
  )
```

```{r}
level_1_metrics_null_adjusted <-
  level_1_metrics_null_adjusted %>%
  select(matches("Metadata_"), one_of(metric_list)) %>%
  select(-Metadata_control_type, -Metadata_reference_or_other)
```


```{r eval=FALSE}
level_1_metrics_null_adjusted %>%
  count(Metadata_Perturbation, Metadata_Cell_type, Metadata_Time, Metadata_broad_sample) %>%
  filter(n > 1)
```

```{r}
level_1_metrics_null_adjusted %>%
  ungroup() %>%
  slice_sample(n = 10) %>%
  rename(
    mAP = sim_retrieval_average_precision_ref_i_mean_i,
    mAP_neglog10_pvalue = sim_retrieval_average_precision_ref_i_nlog10pvalue_mean_i
  )
```
```{r}
level_1_metrics_null_adjusted <-
  level_1_metrics_null_adjusted %>%
  inner_join(
    level_1_metrics_null_adjusted %>%
      distinct(Metadata_Perturbation, Metadata_Time) %>%
      arrange(Metadata_Perturbation, Metadata_Time) %>%
      group_by(Metadata_Perturbation) %>%
      mutate(Metadata_Time_coded = rank(Metadata_Time)) %>%
      ungroup() %>%
      mutate(Metadata_Time_coded = factor(
        Metadata_Time_coded, labels = c("short", "long")
      ))
  )
```


```{r}
level_1_metrics_null_adjusted %>%
  ggplot(aes(sim_retrieval_average_precision_ref_i_mean_i,
             sim_retrieval_average_precision_ref_i_nlog10pvalue_mean_i)) +
  geom_point() +
  facet_grid(Metadata_Perturbation ~ Metadata_Cell_type + Metadata_Time_coded) +
  geom_hline(yintercept = -log10(significance_threshold)) +
  theme_bw()
```

```{r rows.print=20}
level_1_metrics_null_adjusted %>%
  count(Metadata_Perturbation,
        Metadata_Cell_type,
        Metadata_Time)
```

```{r rows.print=20}
level_1_metrics_null_adjusted %>%
  mutate(is_significant = sim_retrieval_average_precision_ref_i_nlog10pvalue_mean_i > 
           -log10(significance_threshold)) %>%
  count(Metadata_Perturbation,
        Metadata_Cell_type,
        Metadata_Time,
        is_significant) %>%
  pivot_wider(names_from = "is_significant", values_from = "n", names_prefix = "significant_") %>%
  mutate(frac_TRUE = round(significant_TRUE / (significant_TRUE + significant_FALSE), 2))
```